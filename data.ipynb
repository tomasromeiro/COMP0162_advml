{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant packages, establish connection to WRDS and set overall configurations for the notebook\n",
    "\n",
    "WRDS Support - https://wrds-www.wharton.upenn.edu/pages/support/programming-wrds/programming-python/querying-wrds-data-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wrds\n",
    "import yfinance as yf \n",
    "\n",
    "# Build WRDS connection\n",
    "\n",
    "db = wrds.Connection(wrds_username='tomasromeiro')\n",
    "#db.close()\n",
    "\n",
    "# Set option to display all columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Set option to force dataframes to display numbers as floats with thousands separators\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)  # Adjust decimal places as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRDS Quick commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List libraries available\n",
    "sorted(db.list_libraries()) \n",
    "\n",
    "# List tables within a library\n",
    "db.list_tables(library=\"cboe\") \n",
    "\n",
    "# describe table metadata\n",
    "db.describe_table(library=\"cboe\", table=\"optprice_2024\") \n",
    "\n",
    "# Execute a sql query against a table (join queries between tables in library can also be performed)\n",
    "data = db.raw_sql('SELECT date, dji FROM djones.djdaily LIMIT 1', date_cols=['date']) \n",
    "\n",
    "# Pass parameters to a sql statement\n",
    "params = {\"tickers\": (\"0015B\", \"0030B\", \"0032A\", \"0033A\", \"0038A\")}\n",
    "data = db.raw_sql(\n",
    "    \"SELECT datadate, gvkey, cusip FROM comp.funda WHERE tic IN %(tickers)s LIMIT 1\",\n",
    "    params=params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. FINRA Short Interest Bimonthly Data  \n",
    "- https://www.finra.org/finra-data/browse-catalog/equity-short-interest/files\n",
    "- https://www.finra.org/finra-data/browse-catalog/equity-short-interest/glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Collate semi monthly datasets\n",
    "If the data has already been collated do not run this and skip to b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = 'data/finra_short_interest_data'\n",
    "output_file = os.path.join(directory, 'collated_short_interest_data.csv')\n",
    "\n",
    "# Check if the collated file already exists and delete it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Get a list of all pipe-delimited CSV files in the directory\n",
    "csv_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith('.csv')]\n",
    "\n",
    "# Read and concatenate all CSV files with proper delimiter handling\n",
    "df_list = []\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        df = pd.read_csv(file, sep='|')  # Read as pipe-delimited with specific dtype\n",
    "        df_list.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {file}: {e}\")\n",
    "\n",
    "if df_list:\n",
    "    short_interest_df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # Replace daysToCoverQuantity with blank where averageDailyVolumeQuantity is 0\n",
    "    short_interest_df.loc[short_interest_df['averageDailyVolumeQuantity'] == 0, 'daysToCoverQuantity'] = None\n",
    "    \n",
    "    # Remove all entries where the ticker (symbolCode) is missing and daysToCoverQuantity is NaN or 999.99 \n",
    "    short_interest_df = short_interest_df.dropna(subset=['symbolCode', 'daysToCoverQuantity'])\n",
    "    short_interest_df = short_interest_df[short_interest_df['daysToCoverQuantity'] != 999.99]\n",
    "\n",
    "    # Keep only stocks not traded Over the Counter\n",
    "    short_interest_df = short_interest_df[short_interest_df['marketClassCode'] != 'OTC']\n",
    "\n",
    "    # Drop unnecessary fields\n",
    "    short_interest_df = short_interest_df.drop(columns=['accountingYearMonthNumber', 'issuerServicesGroupExchangeCode', 'stockSplitFlag', 'revisionFlag', 'changePercent', 'changePreviousNumber', 'previousShortPositionQuantity', 'issueName', 'marketClassCode'])\n",
    "    \n",
    "    # Move settlementDate to the first column\n",
    "    columns = ['settlementDate'] + [col for col in short_interest_df.columns if col != 'settlementDate']\n",
    "    short_interest_df = short_interest_df[columns]\n",
    "\n",
    "    # Sort by settlementDate and symbolCode\n",
    "    short_interest_df = short_interest_df.sort_values(by=['settlementDate', 'symbolCode'])\n",
    "\n",
    "    # Renaming columns\n",
    "    short_interest_df.rename(columns={\"currentShortPositionQuantity\": \"short_volume\"}, inplace=True)\n",
    "    short_interest_df.rename(columns={\"averageDailyVolumeQuantity\": \"avg_daily_volume\"}, inplace=True)\n",
    "    short_interest_df.rename(columns={\"daysToCoverQuantity\": \"days_to_cover\"}, inplace=True)\n",
    "\n",
    "    # Chaging fields to appropriate data type\n",
    "    short_interest_df = short_interest_df.astype({\"short_volume\": \"int32\", \"avg_daily_volume\": \"int32\"})\n",
    "\n",
    "    # Save the collated DataFrame to the same directory\n",
    "    short_interest_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Collated data saved to {output_file}\")\n",
    "else:\n",
    "    print(\"No valid CSV files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Open .csv file to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = 'data/finra_short_interest_data'\n",
    "\n",
    "# Open the collated file in a DataFrame for viewing\n",
    "short_interest_file = os.path.join(directory, 'collated_short_interest_data.csv')\n",
    "short_interest_df = pd.read_csv(short_interest_file)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract tickers and date ranges to use as parameters for remaining data extracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16857 unique tickers in the short interest file\n",
      "Short interest file date range is 2021-06-15 to 2025-01-15\n"
     ]
    }
   ],
   "source": [
    "# Extract unique tickers from the short interest file. Will be used as the main variable to pass through to subsquent queries where tickers are required\n",
    "tickers = short_interest_df['symbolCode'].unique().tolist()\n",
    "print(f\"{len(tickers)} unique tickers in the short interest file\")\n",
    "\n",
    "# Extract earliest and latest date in the short interest file\n",
    "earliest_date = short_interest_df['settlementDate'].min()\n",
    "latest_date = short_interest_df['settlementDate'].max()\n",
    "\n",
    "print(f\"Short interest file date range is {earliest_date} to {latest_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. WRDS (Wharton) Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) Company Data (Quarterly) - Fundamentals\n",
    "https://wrds-www.wharton.upenn.edu/pages/get-data/compustat-capital-iq-standard-poors/compustat/north-america-daily/fundamentals-quarterly/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll extract quarterly financial statement data and derive commonly used metrics if not available directly.\n",
    "\n",
    "Variable references (for the quarterly reporting period, in USD):\n",
    "- conm: company name\n",
    "- tic: company ticker symbol\n",
    "- rdq: report date of quarterly earnings\n",
    "- revtq: total revenue \n",
    "- cogsq: cost of goods sold\n",
    "- oiadpq: operating income after depreciation and amortisation\n",
    "- dlcq: short-term (current) debt\n",
    "- dlttq: long-term debt\n",
    "- cheq: cash and cash equivalents at reporting point in time\n",
    "\n",
    "The variables above will be used to calculated the following metrics:\n",
    "\n",
    "- Gross Margin = (revtq – cogsq) / revtq \n",
    "    - \"revtq\" represents total revenues and \"cogsq\" represents the Cost of Goods Sold both at quarter level. The difference equals gross profit.\n",
    "- EBITDA = oiadpq + dpq\n",
    "    - Earnings Before Interest, Tax, Depreciation and Amortization. Since oiadpq already deducts depreciation and amortisation, adding dpq back returns EBITDA.\n",
    "- Net Debt = (dlcq + dlttq) – che\n",
    "    - Net Debt measures a company’s overall debt situation by offsetting its total debt with its liquid assets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Download data and save it as a .csv so we avoiding repeated long queries to WRDS in case we clear memory. \n",
    "If the data has already been downloaded do not run this and skip to b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to download into\n",
    "directory = 'data/wrds_company_fundamentals_data'\n",
    "output_file = os.path.join(directory, 'wrds_company_fundamentals_data.csv')\n",
    "\n",
    "# Check if the collated file already exists and delete it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Pass parameters to a sql statement\n",
    "params = {\n",
    "    \"tickers\": tuple(tickers),\n",
    "    \"start_date\": earliest_date,\n",
    "    \"end_date\": latest_date\n",
    "}\n",
    "\n",
    "# Query WRDS to fetch data\n",
    "quartely_company_fundamentals_df = db.raw_sql(\n",
    "    \"SELECT rdq as date, tic as ticker, revtq as revenue, ceqq as book_value, niq as net_income, (revtq - cogsq) / NULLIF(revtq, 0) as gross_margin, (revtq - cogsq) / NULLIF(atq, 0) as gross_profitability, \"\n",
    "    \"oiadpq / NULLIF(atq, 0) as operating_profitability, (dlcq + dlttq) / NULLIF(atq, 0) as leverage, dlcq + dlttq - cheq as net_debt, oiadpq + dpq as ebitda, \"\n",
    "    \"(dlcq + dlttq - cheq) / NULLIF((oiadpq + dpq), 0) as netdebt_to_ebitda \" \n",
    "    \"FROM comp_na_daily_current.fundq \" \n",
    "    \"WHERE tic in %(tickers)s and rdq BETWEEN %(start_date)s AND %(end_date)s \",\n",
    "    params=params\n",
    ")\n",
    "#  revtq as rev, cogsq as cogs, oiadpq as op_income, dlcq as st_debt, dlttq as lt_debt, cheq as cash_eq, atq as total_assets, niq as net_income,  - base fields. Keeping only calculated metrics.\n",
    "\n",
    "# Save the DataFrame to the directory\n",
    "quartely_company_fundamentals_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Open .csv file to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = 'data/wrds_company_fundamentals_data'\n",
    "\n",
    "# Open the file in a DataFrame for viewing\n",
    "quartely_company_fundamentals_file = os.path.join(directory, 'wrds_company_fundamentals_data.csv')\n",
    "quartely_company_fundamentals_df = pd.read_csv(quartely_company_fundamentals_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract unique downloaded tickers and compare to unique ticker list derived so far. Delete unmatched tickers from previous datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6086 unique tickers found in WRDS quarterly company fundamentals data\n",
      "16857 unique tickers found in FINRA short interest data\n",
      "10771 tickers missing from the WRDS quarterly company fundamentals compared to the short interest file\n",
      "Updated ticker list. New unique ticker count is: 6086\n"
     ]
    }
   ],
   "source": [
    "# Extract unique tickers from WRDS download\n",
    "quartely_company_fundamentals_tickers = set(quartely_company_fundamentals_df['ticker'].unique().tolist())\n",
    "print(f\"{len(quartely_company_fundamentals_tickers)} unique tickers found in WRDS quarterly company fundamentals data\")\n",
    "\n",
    "# Find missing tickers (tickers in short_interest_df but NOT in quartely_company_fundamentals_df)\n",
    "print(f\"{len(tickers)} unique tickers found in FINRA short interest data\")\n",
    "missing_tickers = set(tickers) - quartely_company_fundamentals_tickers\n",
    "\n",
    "print(f\"{len(missing_tickers)} tickers missing from the WRDS quarterly company fundamentals compared to the short interest file\")\n",
    "\n",
    "# Remove records with missing tickers from short_interest_df and daily stock data\n",
    "short_interest_df = short_interest_df[~short_interest_df['symbolCode'].isin(missing_tickers)]\n",
    "\n",
    "# Update ticker variable\n",
    "tickers = short_interest_df['symbolCode'].unique().tolist()\n",
    "print(f\"Updated ticker list. New unique ticker count is: {len(tickers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii) Stock Data (Daily Level) - Prices and Volume\n",
    "https://wrds-www.wharton.upenn.edu/pages/get-data/compustat-capital-iq-standard-poors/compustat/north-america-daily/security-daily/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Reference:\n",
    "- conm: company name\n",
    "- datadate: record date\n",
    "- tic: ticker symbol\n",
    "- cshoc: shares outstanding\n",
    "- cshtrd: trading Volume - daily\n",
    "- prccd: price - close - daily\n",
    "\n",
    "Filtering the data to fetch only USA stocks in order to be able to inspect the dataset sensibly without the need for currency conversions and consistency of financial statement data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Download data and save it as a .csv so we avoiding repeated long queries to WRDS in case we clear memory. \n",
    "If the data has already been downloaded do not run this and skip to b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory to download into\n",
    "directory = 'data/wrds_stock_daily_data'\n",
    "output_file = os.path.join(directory, 'wrds_stock_daily_data.csv')\n",
    "\n",
    "# Check if the collated file already exists and delete it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Pass parameters to a sql statement\n",
    "params = {\n",
    "    \"tickers\": tuple(tickers),\n",
    "    \"start_date\": earliest_date,\n",
    "    \"end_date\": latest_date\n",
    "}\n",
    "\n",
    "# Query WRDS to fetch data\n",
    "daily_stock_data_df = db.raw_sql(\n",
    "    \"SELECT datadate, conm as company_name, tic as ticker, prccd as price_close, cshtrd as volume, cshoc as shares_outstanding, prccd * cshoc as market_cap, eps \" \n",
    "    \"FROM comp_na_daily_all.secd \" \n",
    "    \"WHERE tic in %(tickers)s and datadate BETWEEN %(start_date)s AND %(end_date)s AND fic = 'USA'\",\n",
    "    params=params\n",
    ")\n",
    "\n",
    "# Save the DataFrame to the directory\n",
    "daily_stock_data_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Open .csv file to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = 'data/wrds_stock_daily_data'\n",
    "\n",
    "# Open the file in a DataFrame for viewing\n",
    "daily_stock_data_file = os.path.join(directory, 'wrds_stock_daily_data.csv')\n",
    "daily_stock_data_df = pd.read_csv(daily_stock_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract unique downloaded tickers and compare to short interest file dataset. Delete unmatched tickers from previous datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4707 unique tickers found in WRDS daily stock data\n",
      "6086 unique tickers found in FINRA short interest data\n",
      "1379 tickers missing from the WRDS daily stock data compared to the short interest file\n",
      "Updated ticker list. New unique ticker count is: 4707\n"
     ]
    }
   ],
   "source": [
    "# Extract unique tickers from WRDS download\n",
    "daily_stock_data_tickers = set(daily_stock_data_df['ticker'].unique().tolist())\n",
    "print(f\"{len(daily_stock_data_tickers)} unique tickers found in WRDS daily stock data\")\n",
    "\n",
    "# Find missing tickers (tickers in ticker list but NOT in daily_stock_data_df)\n",
    "print(f\"{len(tickers)} unique tickers found in FINRA short interest data\")\n",
    "missing_tickers = set(tickers) - daily_stock_data_tickers\n",
    "\n",
    "print(f\"{len(missing_tickers)} tickers missing from the WRDS daily stock data compared to the short interest file\")\n",
    "\n",
    "# Remove records with missing tickers from short_interest_df and quartely_company_fundamentals_df\n",
    "short_interest_df = short_interest_df[~short_interest_df['symbolCode'].isin(missing_tickers)]\n",
    "quartely_company_fundamentals_df = quartely_company_fundamentals_df[~quartely_company_fundamentals_df['ticker'].isin(missing_tickers)]\n",
    "\n",
    "# Update ticker variable\n",
    "tickers = short_interest_df['symbolCode'].unique().tolist()\n",
    "print(f\"Updated ticker list. New unique ticker count is: {len(tickers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Yahoo Finance Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Market Data - S&P500 and VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = 'data/yahoo_finance_sp500_vix_data'\n",
    "output_file = os.path.join(directory, 'yahoo_finance_sp500_vix_data.csv')\n",
    "\n",
    "# Check if the collated file already exists and delete it\n",
    "if os.path.exists(output_file):\n",
    "    os.remove(output_file)\n",
    "\n",
    "# Define ticker symbols\n",
    "tickers = [\"^GSPC\", \"^VIX\"]  # S&P 500 and VIX\n",
    "\n",
    "# Fetch data (Closing Prices and Volume)\n",
    "sp500_vix_data_df = yf.download(tickers, start=earliest_date, end=latest_date, progress=False)[['Close']]\n",
    "\n",
    "# Flatten the MultiIndex to standard column names\n",
    "sp500_vix_data_df.columns = [f\"{col[0]}_{col[1]}\" for col in sp500_vix_data_df.columns]\n",
    "\n",
    "# Rename columns to match the requested format\n",
    "sp500_vix_data_df = sp500_vix_data_df.rename(columns={\n",
    "    'Close_^GSPC': 'sp500_price_close',\n",
    "    'Close_^VIX': 'vix_price_close'\n",
    "})\n",
    "\n",
    "# Reorder columns\n",
    "sp500_vix_data_df = sp500_vix_data_df[['sp500_price_close', 'vix_price_close']]\n",
    "\n",
    "# Format date index to YYYY-MM-DD and reset index\n",
    "sp500_vix_data_df.index = sp500_vix_data_df.index.strftime('%Y-%m-%d')\n",
    "sp500_vix_data_df = sp500_vix_data_df.reset_index()\n",
    "\n",
    "# Rename the date column to 'date'\n",
    "sp500_vix_data_df = sp500_vix_data_df.rename(columns={'index': 'date'})\n",
    "\n",
    "# Save the collated DataFrame to the same directory\n",
    "sp500_vix_data_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Open .csv file to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the CSV files\n",
    "directory = 'data/yahoo_finance_sp500_vix_data'\n",
    "\n",
    "# Open the collated file in a DataFrame for viewing\n",
    "sp500_vix_data_file = os.path.join(directory, 'yahoo_finance_sp500_vix_data.csv')\n",
    "sp500_vix_data_df = pd.read_csv(sp500_vix_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Join datasets and perform data cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Join datasets and fowardfill datapoints where relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns used as join criteria between datasets\n",
    "daily_stock_data_df.rename(columns={\"datadate\": \"date\"}, inplace=True)\n",
    "sp500_vix_data_df.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
    "short_interest_df.rename(columns={\"settlementDate\": \"date\"}, inplace=True)\n",
    "short_interest_df.rename(columns={\"symbolCode\": \"ticker\"}, inplace=True)\n",
    "\n",
    "# Merge stock data and index data on date\n",
    "merged_df = pd.merge(daily_stock_data_df, sp500_vix_data_df, on=\"date\", how=\"left\")\n",
    "\n",
    "# Merge ticker-level data (on date + ticker)\n",
    "merged_df = pd.merge(merged_df, quartely_company_fundamentals_df, on=[\"date\", \"ticker\"], how=\"left\")\n",
    "merged_df = pd.merge(merged_df, short_interest_df, on=[\"date\", \"ticker\"], how=\"left\")\n",
    "\n",
    "# Sort by date and ticker\n",
    "merged_df = merged_df.sort_values(by=[\"date\", \"ticker\"]).reset_index(drop=True)\n",
    "\n",
    "# Forward fill ticker-specific, point-in-time values (e.g. short interest, quarterly gross profit, etc.)\n",
    "ticker_cols = list(merged_df.columns)\n",
    "ticker_cols.remove(\"date\")  # Exclude date column from filling\n",
    "ticker_cols.remove(\"ticker\")  # Exclude ticker column from filling\n",
    "merged_df[ticker_cols] = merged_df.groupby(\"ticker\")[ticker_cols].ffill()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Cleanse dataset and improve readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of tickers with 0 shares outstanding: 1\n",
      "DataFrame shape after removing tickers with 0 shares outstanding: (3800015, 23)\n",
      "Count of tickers where market cap has been below 100,000,000: 1609\n",
      "Final DataFrame shape after removing tickers with low market cap: (2495330, 23)\n",
      "Count of tickers with where quarterly revenue has been below $100,000: 206\n",
      "Final DataFrame shape after removing tickers with low revenue: (2357504, 23)\n",
      "Final count of tickers is: 2891\n"
     ]
    }
   ],
   "source": [
    "# Scale relevant fields from short interest file and daily stock data to millions in order to match the fundamentals file\n",
    "divisor = 1000000\n",
    "cols_to_divide = ['volume', 'shares_outstanding', 'market_cap', 'short_volume', 'avg_daily_volume']\n",
    "\n",
    "# Vectorized operation: divides the specified columns by the divisor.\n",
    "merged_df[cols_to_divide] = merged_df[cols_to_divide] / divisor\n",
    "\n",
    "# Step 1: Identify tickers with 0 shares outstanding.\n",
    "tickers_zero_shares = merged_df.loc[merged_df['shares_outstanding'] == 0, 'ticker'].unique()\n",
    "print(\"Count of tickers with 0 shares outstanding:\", len(tickers_zero_shares))\n",
    "\n",
    "# Remove rows corresponding to these tickers.\n",
    "merged_df = merged_df[~merged_df['ticker'].isin(tickers_zero_shares)].copy()\n",
    "print(\"DataFrame shape after removing tickers with 0 shares outstanding:\", merged_df.shape)\n",
    "\n",
    "# Step 2: Identify tickers with market_cap below $100,000,000.\n",
    "tickers_low_market_cap = merged_df.loc[merged_df['market_cap'] < 100, 'ticker'].unique()\n",
    "print(\"Count of tickers where market cap has been below 100,000,000:\", len(tickers_low_market_cap))\n",
    "\n",
    "# Remove rows corresponding to these tickers.\n",
    "merged_df = merged_df[~merged_df['ticker'].isin(tickers_low_market_cap)].copy()\n",
    "print(\"Final DataFrame shape after removing tickers with low market cap:\", merged_df.shape)\n",
    "\n",
    "# Step 3: Identify tickers where quarterly revenue been below $100,000.\n",
    "tickers_low_revenue = merged_df.loc[merged_df['revenue'] < 0.1, 'ticker'].unique() \n",
    "print(\"Count of tickers with where quarterly revenue has been below $100,000:\", len(tickers_low_revenue))\n",
    "\n",
    "# Remove rows corresponding to these tickers.\n",
    "merged_df = merged_df[~merged_df['ticker'].isin(tickers_low_revenue)].copy()\n",
    "print(\"Final DataFrame shape after removing tickers with low revenue:\", merged_df.shape)\n",
    "\n",
    "# Final count of tickers\n",
    "tickers_final = merged_df['ticker'].unique().tolist()\n",
    "print(f\"Final count of tickers is: {len(tickers_final)}\")\n",
    "\n",
    "# Switch column order for better readability\n",
    "new_order = ['date', 'ticker', 'company_name', 'price_close', 'shares_outstanding', 'market_cap', 'volume', 'short_volume', 'avg_daily_volume', 'days_to_cover',\n",
    "             'sp500_price_close', 'vix_price_close', 'eps', 'book_value', 'revenue', 'gross_margin', 'gross_profitability', 'ebitda', 'operating_profitability', \n",
    "             'net_income', 'netdebt_to_ebitrda', 'leverage'\n",
    "            ],\n",
    "\n",
    "merged_df = merged_df[new_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>shares_outstanding</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>eps</th>\n",
       "      <th>sp500_price_close</th>\n",
       "      <th>vix_price_close</th>\n",
       "      <th>revenue</th>\n",
       "      <th>book_value</th>\n",
       "      <th>net_income</th>\n",
       "      <th>gross_margin</th>\n",
       "      <th>gross_profitability</th>\n",
       "      <th>operating_profitability</th>\n",
       "      <th>leverage</th>\n",
       "      <th>net_debt</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>netdebt_to_ebitda</th>\n",
       "      <th>short_volume</th>\n",
       "      <th>avg_daily_volume</th>\n",
       "      <th>days_to_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1933257</th>\n",
       "      <td>2021-06-15</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>106.11</td>\n",
       "      <td>6.05</td>\n",
       "      <td>268.74</td>\n",
       "      <td>28,516.43</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,246.59</td>\n",
       "      <td>17.02</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933258</th>\n",
       "      <td>2021-06-16</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>105.07</td>\n",
       "      <td>8.96</td>\n",
       "      <td>268.74</td>\n",
       "      <td>28,236.93</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,223.70</td>\n",
       "      <td>18.15</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933259</th>\n",
       "      <td>2021-06-17</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>108.81</td>\n",
       "      <td>6.55</td>\n",
       "      <td>268.74</td>\n",
       "      <td>29,242.03</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,221.86</td>\n",
       "      <td>17.75</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933260</th>\n",
       "      <td>2021-06-18</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>109.12</td>\n",
       "      <td>6.36</td>\n",
       "      <td>268.74</td>\n",
       "      <td>29,325.35</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,166.45</td>\n",
       "      <td>20.70</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933261</th>\n",
       "      <td>2021-06-21</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>108.11</td>\n",
       "      <td>7.87</td>\n",
       "      <td>268.74</td>\n",
       "      <td>29,053.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,224.79</td>\n",
       "      <td>17.89</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933262</th>\n",
       "      <td>2021-06-22</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>117.17</td>\n",
       "      <td>13.08</td>\n",
       "      <td>268.74</td>\n",
       "      <td>31,488.73</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,246.44</td>\n",
       "      <td>16.66</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933263</th>\n",
       "      <td>2021-06-23</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>117.48</td>\n",
       "      <td>7.88</td>\n",
       "      <td>268.74</td>\n",
       "      <td>31,572.05</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,241.84</td>\n",
       "      <td>16.32</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933264</th>\n",
       "      <td>2021-06-24</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>121.85</td>\n",
       "      <td>12.75</td>\n",
       "      <td>268.74</td>\n",
       "      <td>32,746.46</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,266.49</td>\n",
       "      <td>15.97</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933265</th>\n",
       "      <td>2021-06-25</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>121.49</td>\n",
       "      <td>12.45</td>\n",
       "      <td>268.74</td>\n",
       "      <td>32,649.71</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,280.70</td>\n",
       "      <td>15.62</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933266</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>PELOTON INTERACTIVE INC</td>\n",
       "      <td>PTON</td>\n",
       "      <td>126.92</td>\n",
       "      <td>11.07</td>\n",
       "      <td>268.74</td>\n",
       "      <td>34,108.99</td>\n",
       "      <td>0.91</td>\n",
       "      <td>4,290.61</td>\n",
       "      <td>15.76</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>22.35</td>\n",
       "      <td>7.30</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date             company_name ticker  price_close  volume  \\\n",
       "1933257  2021-06-15  PELOTON INTERACTIVE INC   PTON       106.11    6.05   \n",
       "1933258  2021-06-16  PELOTON INTERACTIVE INC   PTON       105.07    8.96   \n",
       "1933259  2021-06-17  PELOTON INTERACTIVE INC   PTON       108.81    6.55   \n",
       "1933260  2021-06-18  PELOTON INTERACTIVE INC   PTON       109.12    6.36   \n",
       "1933261  2021-06-21  PELOTON INTERACTIVE INC   PTON       108.11    7.87   \n",
       "1933262  2021-06-22  PELOTON INTERACTIVE INC   PTON       117.17   13.08   \n",
       "1933263  2021-06-23  PELOTON INTERACTIVE INC   PTON       117.48    7.88   \n",
       "1933264  2021-06-24  PELOTON INTERACTIVE INC   PTON       121.85   12.75   \n",
       "1933265  2021-06-25  PELOTON INTERACTIVE INC   PTON       121.49   12.45   \n",
       "1933266  2021-06-28  PELOTON INTERACTIVE INC   PTON       126.92   11.07   \n",
       "\n",
       "         shares_outstanding  market_cap  eps  sp500_price_close  \\\n",
       "1933257              268.74   28,516.43 0.91           4,246.59   \n",
       "1933258              268.74   28,236.93 0.91           4,223.70   \n",
       "1933259              268.74   29,242.03 0.91           4,221.86   \n",
       "1933260              268.74   29,325.35 0.91           4,166.45   \n",
       "1933261              268.74   29,053.91 0.91           4,224.79   \n",
       "1933262              268.74   31,488.73 0.91           4,246.44   \n",
       "1933263              268.74   31,572.05 0.91           4,241.84   \n",
       "1933264              268.74   32,746.46 0.91           4,266.49   \n",
       "1933265              268.74   32,649.71 0.91           4,280.70   \n",
       "1933266              268.74   34,108.99 0.91           4,290.61   \n",
       "\n",
       "         vix_price_close  revenue  book_value  net_income  gross_margin  \\\n",
       "1933257            17.02     <NA>        <NA>        <NA>          <NA>   \n",
       "1933258            18.15     <NA>        <NA>        <NA>          <NA>   \n",
       "1933259            17.75     <NA>        <NA>        <NA>          <NA>   \n",
       "1933260            20.70     <NA>        <NA>        <NA>          <NA>   \n",
       "1933261            17.89     <NA>        <NA>        <NA>          <NA>   \n",
       "1933262            16.66     <NA>        <NA>        <NA>          <NA>   \n",
       "1933263            16.32     <NA>        <NA>        <NA>          <NA>   \n",
       "1933264            15.97     <NA>        <NA>        <NA>          <NA>   \n",
       "1933265            15.62     <NA>        <NA>        <NA>          <NA>   \n",
       "1933266            15.76     <NA>        <NA>        <NA>          <NA>   \n",
       "\n",
       "         gross_profitability  operating_profitability  leverage  net_debt  \\\n",
       "1933257                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933258                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933259                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933260                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933261                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933262                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933263                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933264                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933265                 <NA>                     <NA>      <NA>      <NA>   \n",
       "1933266                 <NA>                     <NA>      <NA>      <NA>   \n",
       "\n",
       "         ebitda  netdebt_to_ebitda  short_volume  avg_daily_volume  \\\n",
       "1933257    <NA>               <NA>         22.35              7.30   \n",
       "1933258    <NA>               <NA>         22.35              7.30   \n",
       "1933259    <NA>               <NA>         22.35              7.30   \n",
       "1933260    <NA>               <NA>         22.35              7.30   \n",
       "1933261    <NA>               <NA>         22.35              7.30   \n",
       "1933262    <NA>               <NA>         22.35              7.30   \n",
       "1933263    <NA>               <NA>         22.35              7.30   \n",
       "1933264    <NA>               <NA>         22.35              7.30   \n",
       "1933265    <NA>               <NA>         22.35              7.30   \n",
       "1933266    <NA>               <NA>         22.35              7.30   \n",
       "\n",
       "         days_to_cover  \n",
       "1933257           3.06  \n",
       "1933258           3.06  \n",
       "1933259           3.06  \n",
       "1933260           3.06  \n",
       "1933261           3.06  \n",
       "1933262           3.06  \n",
       "1933263           3.06  \n",
       "1933264           3.06  \n",
       "1933265           3.06  \n",
       "1933266           3.06  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merged_df.describe()\n",
    "merged_df[merged_df['ticker'] == 'PTON'].sort_values(by=[\"date\"]).head(10)\n",
    "#len(merged_df['ticker'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99th percentile threshold for 'netdebt_to_ebitda': -117.73723431281226\n",
      "Filtered and sorted DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>company_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>shares_outstanding</th>\n",
       "      <th>market_cap</th>\n",
       "      <th>eps</th>\n",
       "      <th>sp500_price_close</th>\n",
       "      <th>vix_price_close</th>\n",
       "      <th>revenue</th>\n",
       "      <th>book_value</th>\n",
       "      <th>net_income</th>\n",
       "      <th>gross_margin</th>\n",
       "      <th>gross_profitability</th>\n",
       "      <th>operating_profitability</th>\n",
       "      <th>leverage</th>\n",
       "      <th>net_debt</th>\n",
       "      <th>ebitda</th>\n",
       "      <th>netdebt_to_ebitda</th>\n",
       "      <th>short_volume</th>\n",
       "      <th>avg_daily_volume</th>\n",
       "      <th>days_to_cover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3791161</th>\n",
       "      <td>2024-10-09</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>42.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>74.14</td>\n",
       "      <td>3,118.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,792.04</td>\n",
       "      <td>20.86</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791135</th>\n",
       "      <td>2024-09-03</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>37.25</td>\n",
       "      <td>0.23</td>\n",
       "      <td>74.14</td>\n",
       "      <td>2,761.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,528.93</td>\n",
       "      <td>20.72</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791160</th>\n",
       "      <td>2024-10-08</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>40.95</td>\n",
       "      <td>0.15</td>\n",
       "      <td>74.14</td>\n",
       "      <td>3,035.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,751.13</td>\n",
       "      <td>21.42</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791159</th>\n",
       "      <td>2024-10-07</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>41.58</td>\n",
       "      <td>0.23</td>\n",
       "      <td>74.14</td>\n",
       "      <td>3,082.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,695.94</td>\n",
       "      <td>22.64</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791138</th>\n",
       "      <td>2024-09-06</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>37.50</td>\n",
       "      <td>0.36</td>\n",
       "      <td>74.14</td>\n",
       "      <td>2,780.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,408.42</td>\n",
       "      <td>22.38</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791158</th>\n",
       "      <td>2024-10-04</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>40.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>74.14</td>\n",
       "      <td>2,966.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,751.07</td>\n",
       "      <td>19.21</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791147</th>\n",
       "      <td>2024-09-19</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>35.70</td>\n",
       "      <td>0.28</td>\n",
       "      <td>74.14</td>\n",
       "      <td>2,646.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,713.64</td>\n",
       "      <td>16.33</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791134</th>\n",
       "      <td>2024-08-30</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>39.43</td>\n",
       "      <td>0.23</td>\n",
       "      <td>74.14</td>\n",
       "      <td>2,923.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,648.40</td>\n",
       "      <td>15.00</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791154</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>39.35</td>\n",
       "      <td>0.14</td>\n",
       "      <td>74.14</td>\n",
       "      <td>2,917.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,762.48</td>\n",
       "      <td>16.73</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791151</th>\n",
       "      <td>2024-09-25</td>\n",
       "      <td>LIFE360 INC</td>\n",
       "      <td>LIF</td>\n",
       "      <td>39.05</td>\n",
       "      <td>0.18</td>\n",
       "      <td>74.14</td>\n",
       "      <td>2,894.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5,722.26</td>\n",
       "      <td>15.41</td>\n",
       "      <td>84.86</td>\n",
       "      <td>326.72</td>\n",
       "      <td>-10.96</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.16</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-159.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-53,300.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               date company_name ticker  price_close  volume  \\\n",
       "3791161  2024-10-09  LIFE360 INC    LIF        42.07    0.10   \n",
       "3791135  2024-09-03  LIFE360 INC    LIF        37.25    0.23   \n",
       "3791160  2024-10-08  LIFE360 INC    LIF        40.95    0.15   \n",
       "3791159  2024-10-07  LIFE360 INC    LIF        41.58    0.23   \n",
       "3791138  2024-09-06  LIFE360 INC    LIF        37.50    0.36   \n",
       "3791158  2024-10-04  LIFE360 INC    LIF        40.02    0.21   \n",
       "3791147  2024-09-19  LIFE360 INC    LIF        35.70    0.28   \n",
       "3791134  2024-08-30  LIFE360 INC    LIF        39.43    0.23   \n",
       "3791154  2024-09-30  LIFE360 INC    LIF        39.35    0.14   \n",
       "3791151  2024-09-25  LIFE360 INC    LIF        39.05    0.18   \n",
       "\n",
       "         shares_outstanding  market_cap  eps  sp500_price_close  \\\n",
       "3791161               74.14    3,118.86  NaN           5,792.04   \n",
       "3791135               74.14    2,761.53  NaN           5,528.93   \n",
       "3791160               74.14    3,035.83  NaN           5,751.13   \n",
       "3791159               74.14    3,082.53  NaN           5,695.94   \n",
       "3791138               74.14    2,780.06  NaN           5,408.42   \n",
       "3791158               74.14    2,966.88  NaN           5,751.07   \n",
       "3791147               74.14    2,646.62  NaN           5,713.64   \n",
       "3791134               74.14    2,923.14  NaN           5,648.40   \n",
       "3791154               74.14    2,917.21  NaN           5,762.48   \n",
       "3791151               74.14    2,894.97  NaN           5,722.26   \n",
       "\n",
       "         vix_price_close  revenue  book_value  net_income  gross_margin  \\\n",
       "3791161            20.86    84.86      326.72      -10.96          0.77   \n",
       "3791135            20.72    84.86      326.72      -10.96          0.77   \n",
       "3791160            21.42    84.86      326.72      -10.96          0.77   \n",
       "3791159            22.64    84.86      326.72      -10.96          0.77   \n",
       "3791138            22.38    84.86      326.72      -10.96          0.77   \n",
       "3791158            19.21    84.86      326.72      -10.96          0.77   \n",
       "3791147            16.33    84.86      326.72      -10.96          0.77   \n",
       "3791134            15.00    84.86      326.72      -10.96          0.77   \n",
       "3791154            16.73    84.86      326.72      -10.96          0.77   \n",
       "3791151            15.41    84.86      326.72      -10.96          0.77   \n",
       "\n",
       "         gross_profitability  operating_profitability  leverage  net_debt  \\\n",
       "3791161                 0.16                    -0.01      0.00   -159.90   \n",
       "3791135                 0.16                    -0.01      0.00   -159.90   \n",
       "3791160                 0.16                    -0.01      0.00   -159.90   \n",
       "3791159                 0.16                    -0.01      0.00   -159.90   \n",
       "3791138                 0.16                    -0.01      0.00   -159.90   \n",
       "3791158                 0.16                    -0.01      0.00   -159.90   \n",
       "3791147                 0.16                    -0.01      0.00   -159.90   \n",
       "3791134                 0.16                    -0.01      0.00   -159.90   \n",
       "3791154                 0.16                    -0.01      0.00   -159.90   \n",
       "3791151                 0.16                    -0.01      0.00   -159.90   \n",
       "\n",
       "         ebitda  netdebt_to_ebitda  short_volume  avg_daily_volume  \\\n",
       "3791161    0.00         -53,300.00          0.35              0.30   \n",
       "3791135    0.00         -53,300.00          0.18              0.33   \n",
       "3791160    0.00         -53,300.00          0.35              0.30   \n",
       "3791159    0.00         -53,300.00          0.35              0.30   \n",
       "3791138    0.00         -53,300.00          0.18              0.33   \n",
       "3791158    0.00         -53,300.00          0.35              0.30   \n",
       "3791147    0.00         -53,300.00          0.17              0.37   \n",
       "3791134    0.00         -53,300.00          0.18              0.33   \n",
       "3791154    0.00         -53,300.00          0.35              0.30   \n",
       "3791151    0.00         -53,300.00          0.17              0.37   \n",
       "\n",
       "         days_to_cover  \n",
       "3791161           1.18  \n",
       "3791135           1.00  \n",
       "3791160           1.18  \n",
       "3791159           1.18  \n",
       "3791138           1.00  \n",
       "3791158           1.18  \n",
       "3791147           1.00  \n",
       "3791134           1.00  \n",
       "3791154           1.18  \n",
       "3791151           1.00  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume merged_df is already loaded.\n",
    "# For example:\n",
    "# merged_df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Specify the field (column) you're interested in.\n",
    "field_name = 'netdebt_to_ebitda'  # Replace with your actual column name\n",
    "\n",
    "# Calculate the 99th percentile threshold for the chosen field.\n",
    "threshold = merged_df[field_name].quantile(0.01)\n",
    "print(f\"99th percentile threshold for '{field_name}': {threshold}\")\n",
    "\n",
    "# Extract rows where the field's value is greater than or equal to the threshold.\n",
    "filtered_df = merged_df[merged_df[field_name] < threshold]\n",
    "\n",
    "# Sort the filtered DataFrame in descending order by the specified field.\n",
    "sorted_filtered_df = filtered_df.sort_values(by=field_name, ascending=False)\n",
    "\n",
    "# Display the full sorted DataFrame.\n",
    "print(\"Filtered and sorted DataFrame:\")\n",
    "sorted_filtered_df.tail(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
